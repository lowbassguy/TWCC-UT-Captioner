###############################################
#  TWCC Universal Translator - Subtitles App  #
#  Author: Joshua 'lowbass' Sommerfeldt       #
#  (with OpenAI, Whisper, and Tkinter)        #
###############################################

# BANDWIDTH OPTIMIZATION IMPROVEMENTS:
# - Smart speech detection: Only processes complete sentences, not fixed 3-second chunks
# - Rate limiting: Configurable minimum time between API calls (default 5 seconds)
# - Duplicate detection: Avoids re-translating similar/identical text
# - Speech pause detection: Waits for natural speech breaks before processing
# - User controls: Adjustable API rate limit and speech sensitivity settings
# These changes reduce API calls by 80-90% while maintaining reliability

# Core GUI and system imports
import tkinter as tk
from tkinter import ttk, font, messagebox  # ttk for modern widgets, font for text styling, messagebox for dialogs
import threading  # For concurrent audio processing and UI updates
import queue  # Thread-safe communication between audio processing and UI
import time
import os
import json  # For settings file format
import base64  # For encoding encrypted data
import tempfile  # For temporary audio files during processing
import wave  # For audio file creation and manipulation
import glob  # For pattern matching when finding temporary files
from datetime import datetime  # For timestamp formatting in reports


# Audio processing and AI imports
import whisper  # OpenAI's speech-to-text model
import pyaudio  # Low-level audio capture from microphone
import numpy as np  # Numerical operations for audio data
from cryptography.fernet import Fernet  # Symmetric encryption for API key storage
from openai import OpenAI  # OpenAI API client for translation services
from concurrent.futures import ThreadPoolExecutor  # Thread pool for audio processing

class SettingsDialog:
    """
    Modal dialog window for securely configuring the OpenAI API key.
    
    This dialog provides:
    - Secure input field (password-masked by default)
    - Show/hide toggle for API key visibility
    - Input validation (checks for proper OpenAI key format)
    - Modal behavior (blocks interaction with parent window)
    """
    
    def __init__(self, parent):
        """
        Initialize the settings dialog.
        
        Args:
            parent: The parent tkinter window (main app window)
        """
        self.parent = parent
        self.result = None  # Will store the API key if user saves, None if cancelled
        
        # Create modal dialog window
        self.dialog = tk.Toplevel(parent)
        self.dialog.title("Settings - API Configuration")
        self.dialog.geometry("400x200")
        self.dialog.resizable(False, False)  # Fixed size for consistent layout
        self.dialog.transient(parent)  # Stay on top of parent window
        self.dialog.grab_set()  # Make dialog modal (blocks parent interaction)
        
        # Center the dialog relative to parent window
        self.dialog.geometry("+%d+%d" % (parent.winfo_rootx() + 50, parent.winfo_rooty() + 50))
        
        self.setup_ui()
        
    def setup_ui(self):
        """
        Create and layout all UI elements for the settings dialog.
        
        Layout includes:
        - Title label
        - API key input field (password-masked)
        - Show/hide checkbox
        - Save/Cancel buttons
        - Informational text
        """
        # Main container with padding
        main_frame = ttk.Frame(self.dialog, padding="20")
        main_frame.pack(fill=tk.BOTH, expand=True)
        
        # Dialog title
        title_label = ttk.Label(main_frame, text="OpenAI API Configuration", 
                               font=('Arial', 12, 'bold'))
        title_label.pack(pady=(0, 15))
        
        # API Key input section
        ttk.Label(main_frame, text="OpenAI API Key:").pack(anchor=tk.W)
        self.api_key_var = tk.StringVar()  # Variable to hold the API key text
        # Entry field with password masking (show="*")
        self.api_key_entry = ttk.Entry(main_frame, textvariable=self.api_key_var, 
                                      show="*", width=50)
        self.api_key_entry.pack(fill=tk.X, pady=(5, 10))
        
        # Show/Hide API key toggle
        self.show_key = tk.BooleanVar()
        show_check = ttk.Checkbutton(main_frame, text="Show API Key", 
                                    variable=self.show_key, command=self.toggle_key_visibility)
        show_check.pack(anchor=tk.W, pady=(0, 15))
        
        # Button container (right-aligned buttons)
        button_frame = ttk.Frame(main_frame)
        button_frame.pack(fill=tk.X)
        
        # Save and Cancel buttons
        ttk.Button(button_frame, text="Save", command=self.save_settings).pack(side=tk.RIGHT, padx=(5, 0))
        ttk.Button(button_frame, text="Cancel", command=self.cancel).pack(side=tk.RIGHT)
        
        # Information label for user guidance
        info_label = ttk.Label(main_frame, text="Your API key will be stored securely on your local machine.", 
                              font=('Arial', 8), foreground='gray')
        info_label.pack(pady=(15, 0))
        
        # Set focus to the input field for immediate typing
        self.api_key_entry.focus()
        
    def toggle_key_visibility(self):
        """
        Toggle API key visibility in the input field.
        When checked: shows plain text
        When unchecked: shows asterisks (password mode)
        """
        if self.show_key.get():
            self.api_key_entry.configure(show="")  # Show plain text
        else:
            self.api_key_entry.configure(show="*")  # Show asterisks
            
    def save_settings(self):
        """
        Validate and save the API key.
        
        Performs validation:
        - Checks if key is not empty
        - Validates OpenAI key format (must start with 'sk-')
        
        If valid, stores key in self.result and closes dialog.
        If invalid, shows error message and keeps dialog open.
        """
        api_key = self.api_key_var.get().strip()
        
        # Validation: empty key
        if not api_key:
            messagebox.showerror("Error", "Please enter your OpenAI API Key")
            return
            
        # Validation: OpenAI key format
        if not api_key.startswith('sk-'):
            messagebox.showerror("Error", "Invalid API Key format. OpenAI keys start with 'sk-'")
            return
            
        # Store result and close dialog
        self.result = api_key
        self.dialog.destroy()
        
    def cancel(self):
        """Close the dialog without saving (result remains None)."""
        self.dialog.destroy()

class SecureSettings:
    """
    Handles secure storage and retrieval of application settings, particularly the OpenAI API key.
    
    Security features:
    - Uses Fernet (symmetric encryption) to encrypt sensitive data
    - Stores files in user's home directory in a hidden folder
    - Generates unique encryption key per installation
    - Base64 encoding for safe file storage
    
    File structure:
    ~/.twcc_captioner/
    ‚îú‚îÄ‚îÄ config.enc    # Encrypted settings (JSON format)
    ‚îî‚îÄ‚îÄ key.key       # Encryption key (binary)
    """
    
    def __init__(self):
        """
        Initialize the settings manager and create necessary directories.
        
        Sets up file paths:
        - settings_dir: Hidden folder in user's home directory
        - settings_file: Encrypted configuration file
        - key_file: Encryption key file
        """
        # Create settings directory path in user's home folder (hidden folder)
        self.settings_dir = os.path.join(os.path.expanduser("~"), ".twcc_captioner")
        self.settings_file = os.path.join(self.settings_dir, "config.enc")  # Encrypted settings
        self.key_file = os.path.join(self.settings_dir, "key.key")  # Encryption key
        self.ensure_settings_dir()
        
    def ensure_settings_dir(self):
        """Create the settings directory if it doesn't exist."""
        if not os.path.exists(self.settings_dir):
            os.makedirs(self.settings_dir)
            print(f"üìÅ [SETTINGS] Created settings directory: {self.settings_dir}")
            
    def get_or_create_key(self):
        """
        Get existing encryption key or create a new one.
        
        Returns:
            bytes: The encryption key for Fernet cipher
            
        Note: Each installation gets a unique key, making encrypted files
        non-transferable between different installations (additional security).
        """
        if os.path.exists(self.key_file):
            # Load existing key
            with open(self.key_file, 'rb') as f:
                return f.read()
        else:
            # Generate new key for first-time setup
            key = Fernet.generate_key()
            with open(self.key_file, 'wb') as f:
                f.write(key)
            print("üîê [SETTINGS] Generated new encryption key")
            return key
            
    def save_api_key(self, api_key):
        """
        Encrypt and save the OpenAI API key to disk.
        
        Args:
            api_key (str): The OpenAI API key to encrypt and store
            
        Returns:
            bool: True if successful, False if error occurred
            
        Process:
        1. Get/create encryption key
        2. Encrypt the API key using Fernet cipher
        3. Base64 encode the encrypted data for safe JSON storage
        4. Save to encrypted settings file
        """
        try:
            # Get encryption key
            key = self.get_or_create_key()
            cipher = Fernet(key)
            
            # Encrypt the API key
            encrypted_key = cipher.encrypt(api_key.encode())
            
            # Create settings dictionary with base64-encoded encrypted key
            settings = {"api_key": base64.b64encode(encrypted_key).decode()}
            
            # Save to file as JSON
            with open(self.settings_file, 'w') as f:
                json.dump(settings, f)
            print("üíæ [SETTINGS] API key saved securely")
            return True
        except Exception as e:
            print(f"‚ùå [SETTINGS] Error saving API key: {e}")
            return False
            
    def load_api_key(self):
        """
        Load and decrypt the OpenAI API key from disk.
        
        Returns:
            str: The decrypted API key, or None if not found/error
            
        Process:
        1. Check if both settings and key files exist
        2. Load encryption key
        3. Load encrypted settings from JSON
        4. Base64 decode and decrypt the API key
        5. Return decrypted key as string
        """
        try:
            # Check if required files exist
            if not os.path.exists(self.settings_file) or not os.path.exists(self.key_file):
                return None
                
            # Load encryption key
            with open(self.key_file, 'rb') as f:
                key = f.read()
                
            # Load encrypted settings
            with open(self.settings_file, 'r') as f:
                settings = json.load(f)
                
            # Decrypt the API key
            cipher = Fernet(key)
            encrypted_key = base64.b64decode(settings["api_key"].encode())
            api_key = cipher.decrypt(encrypted_key).decode()
            
            print("üîì [SETTINGS] API key loaded successfully")
            return api_key
        except Exception as e:
            print(f"‚ùå [SETTINGS] Error loading API key: {e}")
            return None

    def save_ui_preferences(self, bg_color, text_color, font_size, language, recent_languages=None, auto_clear_enabled=False, auto_clear_timeout=5):
        """
        Save UI preferences to local file.
        
        Args:
            bg_color (str): Background color selection
            text_color (str): Text color selection  
            font_size (int): Font size value
            language (str): Selected language
            recent_languages (list): List of recently used languages
            auto_clear_enabled (bool): Auto-clear enabled state
            auto_clear_timeout (int): Auto-clear timeout duration in seconds
            
        Returns:
            bool: True if successful, False if error occurred
        """
        try:
            ui_settings_file = os.path.join(self.settings_dir, "ui_preferences.json")
            
            preferences = {
                "background_color": bg_color,
                "text_color": text_color,
                "font_size": font_size,
                "language": language,
                "recent_languages": recent_languages or [],
                "auto_clear_enabled": auto_clear_enabled,
                "auto_clear_timeout": auto_clear_timeout
            }
            
            with open(ui_settings_file, 'w') as f:
                json.dump(preferences, f, indent=2)
            
            print("üíæ [SETTINGS] UI preferences saved")
            return True
            
        except Exception as e:
            print(f"‚ùå [SETTINGS] Error saving UI preferences: {e}")
            return False

    def load_ui_preferences(self):
        """
        Load UI preferences from local file.
        
        Returns:
            dict: Dictionary with UI preference values, or None if not found/error
        """
        try:
            ui_settings_file = os.path.join(self.settings_dir, "ui_preferences.json")
            
            if not os.path.exists(ui_settings_file):
                print("üìÇ [SETTINGS] No UI preferences file found - using defaults")
                return None
                
            with open(ui_settings_file, 'r') as f:
                preferences = json.load(f)
            
            print("üîì [SETTINGS] UI preferences loaded successfully")
            return preferences
            
        except Exception as e:
            print(f"‚ùå [SETTINGS] Error loading UI preferences: {e}")
            return None

class SubtitleApp:
    """
    Main application class for the TWCC Universal Translator.
    
    This application provides real-time speech-to-text transcription with translation
    capabilities for live streaming. It captures audio from the microphone, transcribes
    it using OpenAI's Whisper model, translates it using GPT, and displays the results
    in a customizable overlay window.
    
    Key features:
    - Real-time audio capture and processing
    - Multi-language translation support
    - Customizable overlay window (colors, fonts, positioning)
    - Secure API key management
    - Threaded processing for responsive UI
    
    Architecture:
    - Main UI thread: Handles user interface and display
    - Recording thread: Continuous audio capture
    - Audio processing thread: Whisper transcription
    - Translation thread: GPT formatting and translation
    - Thread-safe queues for communication between components
    """
    
    def __init__(self, root):
        """
        Initialize the main application.
        
        Args:
            root: The main tkinter window
            
        Initialization process:
        1. Set up window properties
        2. Initialize secure settings manager
        3. Load/initialize OpenAI client
        4. Load Whisper model
        5. Configure audio settings
        6. Set up UI components
        7. Start background processing threads
        """
        print("üÜï [INIT] Initializing SubtitleApp üê£")
        self.root = root
        self.root.title("TWCC Universal Translator - Subtitles")
        self.root.attributes('-topmost', True)  # Keep window on top for streaming overlay
        
        # Initialize secure settings manager
        self.settings = SecureSettings()

        # OpenAI client initialization with settings-based API key
        self.client = None
        self.init_openai_client()

        # Whisper model initialization for speech-to-text
        try:
            print("üé§ [INIT] Loading Whisper model... üïó")
            # Load base model (good balance of speed vs accuracy for real-time use)
            self.whisper_model = whisper.load_model("base")
            print("‚úÖ [INIT] Whisper model loaded successfully!")
        except Exception as e:
            print(f"‚ùå [INIT] Failed to load Whisper model: {e}")
            self.whisper_model = None

        # Audio capture configuration
        self.CHUNK = 1024  # Audio buffer size (smaller = more responsive, larger = more efficient)
        self.FORMAT = pyaudio.paInt16  # 16-bit audio format
        self.CHANNELS = 1  # Mono audio (sufficient for speech recognition)
        self.RATE = 16000  # 16kHz sample rate (optimal for Whisper)
        self.RECORD_SECONDS = 3  # Length of each audio chunk for processing
        
        # NEW: Smart speech detection to reduce API calls
        self.MIN_SPEECH_LENGTH = 1.0  # Minimum seconds of speech before processing (reduced from 2.0)
        self.SILENCE_THRESHOLD = 1.0  # Seconds of silence before processing accumulated speech (reduced from 2.0)
        self.speech_buffer = []  # Buffer to accumulate speech until silence
        self.last_speech_time = 0  # Track when we last detected speech
        self.silence_start_time = None  # Track when silence started
        
        # NEW: Rate limiting to prevent API spam
        self.last_api_call_time = 0
        self.min_api_interval = 3.0  # Minimum 3 seconds between API calls (reduced from 5.0)
        
        # NEW: Duplicate detection to avoid re-translating same text
        self.recent_translations = []  # Keep last 5 translations
        self.max_recent_translations = 5
        
        print("üéµ [INIT] Initializing PyAudio üé∂")
        self.audio = pyaudio.PyAudio()  # Audio interface
        
        # Clean up any leftover temporary files from previous runs
        self.cleanup_temp_files()
        
        # Thread-safe queues for inter-thread communication
        self.text_queue = queue.Queue()  # UI updates (processed text to display)
        self.audio_task_queue = queue.Queue()  # Audio chunks for processing
        self.translation_task_queue = queue.Queue()  # Text for translation
        
        # Application state
        self.is_recording = False  # Recording state flag
        
        # Subtitle auto-clear functionality
        self.subtitle_timeout_seconds = tk.IntVar(value=5)  # Default 5 seconds
        self.auto_clear_enabled = tk.BooleanVar(value=True)  # Auto-clear enabled by default
        self.clear_timer_id = None  # Track scheduled clear operation
        
        # Token usage tracking for cost estimation
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.total_cost = 0.0
        self.session_translations = 0
        
        # Session tracking for reporting
        self.session_start_time = None
        self.session_end_time = None
        
        # Comprehensive language support (based on Google Translate 2024 language list)
        # Dictionary maps display names to language codes for OpenAI API
        self.languages = {
            "Abkhaz": "ab", "Acehnese": "ace", "Acholi": "ach", "Afar": "aa", "Afrikaans": "af",
            "Albanian": "sq", "Alur": "alz", "Amharic": "am", "Arabic": "ar", "Armenian": "hy",
            "Assamese": "as", "Avar": "av", "Awadhi": "awa", "Aymara": "ay", "Azerbaijani": "az",
            "Balinese": "ban", "Baluchi": "bal", "Bambara": "bm", "Baoul√©": "bci", "Bashkir": "ba",
            "Basque": "eu", "Batak Karo": "btx", "Batak Simalungun": "bts", "Batak Toba": "bbc",
            "Belarusian": "be", "Bemba": "bem", "Bengali": "bn", "Betawi": "bew", "Bhojpuri": "bho",
            "Bikol": "bik", "Bosnian": "bs", "Breton": "br", "Bulgarian": "bg", "Buryat": "bua",
            "Cantonese": "yue", "Catalan": "ca", "Cebuano": "ceb", "Chamorro": "ch", "Chechen": "ce",
            "Chichewa": "ny", "Chinese (Simplified)": "zh-CN", "Chinese (Traditional)": "zh-TW",
            "Chuukese": "chk", "Chuvash": "cv", "Corsican": "co", "Crimean Tatar": "crh",
            "Croatian": "hr", "Czech": "cs", "Danish": "da", "Dari": "prs", "Dhivehi": "dv",
            "Dinka": "din", "Dogri": "doi", "Dombe": "dov", "Dutch": "nl", "Dyula": "dyu",
            "Dzongkha": "dz", "English": "en", "Esperanto": "eo", "Estonian": "et", "Ewe": "ee",
            "Faroese": "fo", "Fijian": "fj", "Filipino": "fil", "Finnish": "fi", "Fon": "fon",
            "French": "fr", "Friulian": "fur", "Fulani": "ff", "Ga": "gaa", "Galician": "gl",
            "Ganda": "lg", "Georgian": "ka", "German": "de", "Greek": "el", "Guarani": "gn",
            "Gujarati": "gu", "Hakha Chin": "cnh", "Hausa": "ha", "Hawaiian": "haw", "Hebrew": "he",
            "Hiligaynon": "hil", "Hindi": "hi", "Hmong": "hmn", "Hungarian": "hu", "Hunsrik": "hrx",
            "Iban": "iba", "Icelandic": "is", "Igbo": "ig", "Ilocano": "ilo", "Indonesian": "id",
            "Irish": "ga", "Italian": "it", "Jamaican Patois": "jam", "Japanese": "ja", "Javanese": "jv",
            "Jingpo": "kac", "Kalaallisut": "kl", "Kannada": "kn", "Kanuri": "kr", "Kapampangan": "pam",
            "Kashmiri": "ks", "Kazakh": "kk", "Khasi": "kha", "Khmer": "km", "Kiga": "cgg",
            "Kikongo": "kg", "Kinyarwanda": "rw", "Kirghiz": "ky", "Kituba": "ktu", "Kokborok": "trp",
            "Komi": "kv", "Konkani": "gom", "Korean": "ko", "Krio": "kri", "Kurdish (Kurmanji)": "ku",
            "Kurdish (Sorani)": "ckb", "Lao": "lo", "Latgalian": "ltg", "Latin": "la", "Latvian": "lv",
            "Ligurian": "lij", "Limburgish": "li", "Lingala": "ln", "Lithuanian": "lt", "Lombard": "lmo",
            "Luo": "luo", "Luxembourgish": "lb", "Macedonian": "mk", "Madurese": "mad", "Makassar": "mak",
            "Malagasy": "mg", "Malay": "ms", "Malay (Jawi)": "ms-Arab", "Malayalam": "ml", "Maltese": "mt",
            "Manx": "gv", "Maori": "mi", "Marathi": "mr", "Marshallese": "mh", "Marwadi": "mwr",
            "Mauritian Creole": "mfe", "Meadow Mari": "chm", "Meiteilon": "mni", "Minang": "min",
            "Mizo": "lus", "Mongolian": "mn", "Myanmar": "my", "Nahuatl": "nah", "Ndau": "ndc",
            "Ndebele (South)": "nr", "Nepali": "ne", "Nepalbhasa": "new", "NKo": "nqo", "Norwegian": "no",
            "Nuer": "nus", "Occitan": "oc", "Odia": "or", "Oromo": "om", "Ossetian": "os",
            "Pangasinan": "pag", "Papiamento": "pap", "Pashto": "ps", "Persian": "fa", "Polish": "pl",
            "Portuguese": "pt", "Portuguese (Portugal)": "pt-PT", "Punjabi": "pa", "Punjabi (Shahmukhi)": "pa-Arab",
            "Q'eqchi'": "quc", "Quechua": "qu", "Romani": "rom", "Romanian": "ro", "Rundi": "rn",
            "Russian": "ru", "Sami (North)": "se", "Samoan": "sm", "Sango": "sg", "Sanskrit": "sa",
            "Santali": "sat", "Scots Gaelic": "gd", "Serbian": "sr", "Sesotho": "st", "Seychellois Creole": "crs",
            "Shan": "shn", "Shona": "sn", "Sicilian": "scn", "Silesian": "szl", "Sindhi": "sd",
            "Sinhala": "si", "Slovak": "sk", "Slovenian": "sl", "Somali": "so", "Spanish": "es",
            "Sundanese": "su", "Susu": "sus", "Swahili": "sw", "Swati": "ss", "Swedish": "sv",
            "Tahitian": "ty", "Tajik": "tg", "Tamil": "ta", "Tamazight": "tzm", "Tamazight (Tifinagh)": "tzm-Tfng",
            "Tatar": "tt", "Telugu": "te", "Tetum": "tet", "Thai": "th", "Tibetan": "bo",
            "Tigrinya": "ti", "Tiv": "tiv", "Tok Pisin": "tpi", "Tongan": "to", "Tsonga": "ts",
            "Tswana": "tn", "Tulu": "tcy", "Tumbuka": "tum", "Turkish": "tr", "Turkmen": "tk",
            "Tuvan": "tyv", "Twi": "tw", "Udmurt": "udm", "Ukrainian": "uk", "Urdu": "ur",
            "Uyghur": "ug", "Uzbek": "uz", "Venda": "ve", "Venetian": "vec", "Vietnamese": "vi",
            "Waray": "war", "Welsh": "cy", "Wolof": "wo", "Xhosa": "xh", "Yakut": "sah",
            "Yiddish": "yi", "Yoruba": "yo", "Yucatec Maya": "yua", "Zapotec": "zap", "Zulu": "zu"
        }
        self.selected_language = tk.StringVar(value="English")  # Currently selected target language
        self.recent_languages = []  # Track recently used languages (up to 5)
        
        # Set default font family (system fonts only)
        self.font_family = "Arial"
        self.custom_font_loaded = False
        
        print("üñºÔ∏è [INIT] Setting up UI üé®")
        self.setup_ui()
        
        # Load and apply saved UI preferences
        self.load_ui_preferences()
        
        # Start background processing threads
        print("üîÅ [INIT] Starting update_text_loop thread ‚è©")
        # UI update thread - monitors text queue and updates display
        self.update_thread = threading.Thread(target=self.update_text_loop, daemon=True)
        self.update_thread.start()
        
        print("üßµ [INIT] Starting audio processing thread pool")
        # Thread pool for CPU-intensive audio processing
        self.audio_executor = ThreadPoolExecutor(max_workers=1)
        # Worker thread that monitors audio queue and submits processing jobs
        self.audio_processing_thread = threading.Thread(target=self.audio_worker, daemon=True)
        self.audio_processing_thread.start()
        
        print("üßµ [INIT] Starting translation worker thread")
        # Translation worker thread - handles OpenAI API calls
        self.translation_worker_thread = threading.Thread(target=self.translation_worker, daemon=True)
        self.translation_worker_thread.start()

    def init_openai_client(self):
        """
        Initialize or reinitialize the OpenAI client with the stored API key.
        
        This method is called:
        - During app startup
        - After user saves a new API key in settings
        
        Process:
        1. Load API key from secure storage
        2. Create OpenAI client if key exists
        3. Handle any initialization errors gracefully
        """
        # Load API key from encrypted settings
        api_key = self.settings.load_api_key()
        if api_key:
            try:
                print("ü§ñ [INIT] Creating OpenAI client ‚ú®")
                self.client = OpenAI(api_key=api_key)
                print("‚úÖ [INIT] OpenAI client created successfully!")
            except Exception as e:
                print(f"‚ùå [INIT] Failed to create OpenAI client: {e}")
                self.client = None
        else:
            print("‚ùå [INIT] OpenAI API key not found in settings")

    def create_subtitle_font(self, size):
        """
        Create a subtitle font using system fonts.
        
        Args:
            size (int): Font size
            
        Returns:
            tkinter.font.Font: The created font object
        """
        try:
            # Try Arial first (widely available), then fallback to system default
            subtitle_font = font.Font(family="Arial", size=size, weight="bold")
            print(f"‚úÖ [FONTS] Using Arial font (size: {size})")
            return subtitle_font
        except Exception as e:
            print(f"‚ö†Ô∏è [FONTS] Arial failed, using system default: {e}")
            return font.Font(size=size, weight="bold")

    def show_settings_dialog(self):
        """
        Display the settings dialog for API key configuration.
        
        Process:
        1. Create and show modal settings dialog
        2. Wait for user to save or cancel
        3. If saved, encrypt and store the new API key
        4. Reinitialize OpenAI client with new key
        5. Show success/error feedback to user
        """
        dialog = SettingsDialog(self.root)
        self.root.wait_window(dialog.dialog)  # Block until dialog closes
        
        if dialog.result:  # User clicked Save (not Cancel)
            if self.settings.save_api_key(dialog.result):
                messagebox.showinfo("Success", "API key saved successfully!")
                self.init_openai_client()  # Reinitialize client with new key
            else:
                messagebox.showerror("Error", "Failed to save API key")

    def setup_ui(self):
        """
        Create and layout the main user interface.
        
        UI Components:
        - Control panel: Language selection, recording controls, appearance settings
        - Settings button: For API key configuration
        - Text display area: Large subtitle display with customizable appearance
        
        Layout uses tkinter grid system for responsive design.
        """
        print("üéõÔ∏è [UI] Setting up control frame and widgets üß©")
        
        # Top control panel with all user controls
        control_frame = ttk.Frame(self.root, padding="10")
        control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E))
        
        # Language selection dropdown
        ttk.Label(control_frame, text="Output Language:").grid(row=0, column=0, padx=5)
        self.language_menu = ttk.Combobox(control_frame, textvariable=self.selected_language, 
                                         values=self.get_language_menu_list(), width=35)
        self.language_menu.grid(row=0, column=1, padx=5)
        self.language_menu.bind('<<ComboboxSelected>>', self.on_language_changed)
        
        # Recording start/stop button
        self.record_button = ttk.Button(control_frame, text="Start Recording", 
                                       command=self.toggle_recording)
        self.record_button.grid(row=0, column=2, padx=5)
        
        # Background color selection for subtitle display
        ttk.Label(control_frame, text="Window:").grid(row=0, column=3, padx=5)
        self.bg_color = tk.StringVar(value="black")
        bg_colors = ["black", "green", "blue", "magenta"]  # Colors suitable for overlays
        bg_menu = ttk.Combobox(control_frame, textvariable=self.bg_color, 
                              values=bg_colors, width=10)
        bg_menu.grid(row=0, column=4, padx=5)
        bg_menu.bind('<<ComboboxSelected>>', self.update_background)
        
        # Text color selection for subtitle display
        ttk.Label(control_frame, text="Text:").grid(row=0, column=5, padx=5)
        self.text_color = tk.StringVar(value="white")
        text_colors = ["white", "yellow", "cyan", "red", "green", "orange", "pink"]  # High contrast colors
        text_menu = ttk.Combobox(control_frame, textvariable=self.text_color, 
                                values=text_colors, width=10)
        text_menu.grid(row=0, column=6, padx=5)
        text_menu.bind('<<ComboboxSelected>>', self.update_text_color)
        
        # Font size adjustment for subtitle readability
        ttk.Label(control_frame, text="Font Size:").grid(row=0, column=7, padx=5)
        self.font_size = tk.IntVar(value=24)  # Default size good for streaming
        font_spinner = ttk.Spinbox(control_frame, from_=12, to=48, 
                                  textvariable=self.font_size, width=10,
                                  command=self.update_font)
        font_spinner.grid(row=0, column=8, padx=5)
        
        # Settings button for API key configuration
        settings_button = ttk.Button(control_frame, text="Settings", 
                                   command=self.show_settings_dialog)
        settings_button.grid(row=0, column=9, padx=5)
        
        # Second row for subtitle auto-clear controls
        ttk.Label(control_frame, text="Auto-clear subtitles:").grid(row=1, column=0, padx=5, sticky=tk.W)
        
        # Auto-clear enable/disable checkbox
        auto_clear_check = ttk.Checkbutton(control_frame, text="Enabled", 
                                         variable=self.auto_clear_enabled,
                                         command=self.on_auto_clear_changed)
        auto_clear_check.grid(row=1, column=1, padx=5, sticky=tk.W)
        
        # Timeout duration spinner
        ttk.Label(control_frame, text="Timeout (seconds):").grid(row=1, column=2, padx=5, sticky=tk.W)
        timeout_spinner = ttk.Spinbox(control_frame, from_=2, to=15, 
                                    textvariable=self.subtitle_timeout_seconds, 
                                    width=10,
                                    command=self.on_timeout_changed)
        timeout_spinner.grid(row=1, column=3, padx=5, sticky=tk.W)
        
        # NEW: Bandwidth control section (Row 2)
        ttk.Label(control_frame, text="API Rate Limit:").grid(row=2, column=0, padx=5, sticky=tk.W)
        self.api_rate_var = tk.DoubleVar(value=self.min_api_interval)
        rate_spinner = ttk.Spinbox(control_frame, from_=3.0, to=30.0, increment=1.0,
                                 textvariable=self.api_rate_var, width=10,
                                 command=self.on_rate_limit_changed)
        rate_spinner.grid(row=2, column=1, padx=5, sticky=tk.W)
        ttk.Label(control_frame, text="seconds").grid(row=2, column=2, padx=5, sticky=tk.W)
        
        # Speech sensitivity control
        ttk.Label(control_frame, text="Speech Pause:").grid(row=2, column=3, padx=5, sticky=tk.W)
        self.pause_threshold_var = tk.DoubleVar(value=self.SILENCE_THRESHOLD)
        pause_spinner = ttk.Spinbox(control_frame, from_=0.5, to=3.0, increment=0.5,
                                  textvariable=self.pause_threshold_var, width=10,
                                  command=self.on_pause_threshold_changed)
        pause_spinner.grid(row=2, column=4, padx=5, sticky=tk.W)
        ttk.Label(control_frame, text="seconds").grid(row=2, column=5, padx=5, sticky=tk.W)
        
        # Main subtitle display area
        self.text_frame = tk.Frame(self.root, bg="black", height=150)
        self.text_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=10, pady=10)
        self.text_frame.grid_propagate(False)  # Maintain fixed height
        
        # Subtitle text font configuration
        self.subtitle_font = self.create_subtitle_font(24)
        
        # For streaming overlay - start with blank display (no distracting text)
        initial_text = ""
            
        # Main subtitle label with word wrapping and center alignment
        self.text_label = tk.Label(self.text_frame, text=initial_text, 
                                  fg="white", bg="black", font=self.subtitle_font,
                                  wraplength=780, justify=tk.CENTER)
        self.text_label.pack(expand=True, fill=tk.BOTH, padx=10, pady=10)
        
        # Configure responsive layout
        self.root.columnconfigure(0, weight=1)  # Allow horizontal expansion
        self.root.rowconfigure(1, weight=1)  # Allow subtitle area to expand
        self.root.minsize(800, 300)  # Increased minimum height for new controls
        print("‚úÖ [UI] UI setup complete! ü•≥")

    def update_background(self, event=None):
        """
        Update the background color of the subtitle display area.
        
        Called when user selects a different background color from the dropdown.
        Updates both the frame and label backgrounds to maintain consistency.
        """
        color = self.bg_color.get()
        print(f"üåà [UI] Background color changed to: {color}")
        self.text_frame.configure(bg=color)
        self.text_label.configure(bg=color)
        # Save preferences when changed
        self.save_ui_preferences()

    def update_text_color(self, event=None):
        """
        Update the text color of the subtitle display.
        
        Called when user selects a different text color from the dropdown.
        Updates the foreground color of the subtitle text.
        """
        color = self.text_color.get()
        print(f"üé® [UI] Text color changed to: {color}")
        self.text_label.configure(fg=color)
        # Save preferences when changed
        self.save_ui_preferences()

    def update_font(self):
        """
        Update the font size of the subtitle text.
        
        Called when user adjusts the font size spinner.
        Immediately applies the new size to the subtitle display.
        """
        print(f"üî† [UI] Font size changed to: {self.font_size.get()} px")
        
        # Recreate the font with the new size
        self.subtitle_font = self.create_subtitle_font(self.font_size.get())
        
        # Update the label to use the new font
        self.text_label.configure(font=self.subtitle_font)
        
        # Save preferences when changed
        self.save_ui_preferences()

    def get_language_menu_list(self):
        """
        Generate the language menu list with recent languages, then most common, then alphabetical.
        
        Structure:
        1. Recent languages (last 5 selected)
        2. 20 most commonly spoken world languages
        3. All remaining languages alphabetically
        
        Returns:
            list: Language names in the specified order
        """
        # Get recent languages that are still valid (up to 5)
        valid_recent = [lang for lang in self.recent_languages[:5] if lang in self.languages]
        
        # 20 most commonly spoken languages in the world
        most_common_languages = [
            "Arabic", "Bengali", "Chinese (Simplified)", "English", "French", 
            "German", "Hindi", "Indonesian", "Italian", "Japanese", "Javanese", 
            "Korean", "Malay", "Marathi", "Portuguese", "Punjabi", "Russian", 
            "Spanish", "Tamil", "Turkish"
        ]
        
        # Filter to only include languages that exist in our dictionary and aren't in recent
        valid_common = [lang for lang in most_common_languages 
                       if lang in self.languages and lang not in valid_recent]
        
        # Get all remaining languages alphabetically
        used_languages = set(valid_recent + valid_common)
        remaining_languages = sorted([lang for lang in self.languages.keys() 
                                    if lang not in used_languages])
        
        # Build the final menu list
        menu_list = []
        
        # Add recent languages section
        if valid_recent:
            menu_list.append("--- Recent Languages ---")
            menu_list.extend(valid_recent)
        
        # Add most common languages section
        if valid_common:
            menu_list.append("--- Most Common Languages ---")
            menu_list.extend(valid_common)
        
        # Add remaining languages alphabetically
        if remaining_languages:
            menu_list.append("--- All Other Languages ---")
            menu_list.extend(remaining_languages)
        
        return menu_list

    def update_recent_languages(self, selected_language):
        """
        Update the recent languages list with the newly selected language.
        
        Args:
            selected_language (str): The language that was just selected
        """
        # Skip if it's any separator line
        if selected_language in ["--- Recent Languages ---", "--- Most Common Languages ---", "--- All Other Languages ---"]:
            return
            
        # Remove the language if it's already in the list (to move it to front)
        if selected_language in self.recent_languages:
            self.recent_languages.remove(selected_language)
        
        # Add to the front of the list
        self.recent_languages.insert(0, selected_language)
        
        # Keep only the last 5 recent languages
        self.recent_languages = self.recent_languages[:5]
        
        # Update the dropdown menu values
        self.language_menu.configure(values=self.get_language_menu_list())
        
        print(f"üìù [UI] Recent languages updated: {self.recent_languages}")

    def on_language_changed(self, event=None):
        """
        Handle language selection changes.
        
        Called when user selects a different language from the dropdown.
        Updates recent languages and saves preferences immediately.
        """
        selected = self.selected_language.get()
        
        # Handle separator selections - reset to previous valid selection
        if selected in ["--- Recent Languages ---", "--- Most Common Languages ---", "--- All Other Languages ---"]:
            # Find a valid language to set (first recent, or English, or first common)
            if self.recent_languages:
                self.selected_language.set(self.recent_languages[0])
            elif "English" in self.languages:
                self.selected_language.set("English")
            else:
                # Fallback to first common language
                common_langs = ["Arabic", "Bengali", "Chinese (Simplified)", "English", "French"]
                for lang in common_langs:
                    if lang in self.languages:
                        self.selected_language.set(lang)
                        break
            return
        
        print(f"üåç [UI] Language changed to: {selected}")
        
        # Update recent languages list
        self.update_recent_languages(selected)
        
        # Save preferences when changed
        self.save_ui_preferences()

    def on_auto_clear_changed(self):
        """
        Handle auto-clear enable/disable changes.
        
        Called when user toggles the auto-clear checkbox.
        Cancels any pending clear timer if auto-clear is disabled.
        """
        enabled = self.auto_clear_enabled.get()
        print(f"‚è∞ [UI] Auto-clear changed to: {'Enabled' if enabled else 'Disabled'}")
        
        # Cancel pending clear timer if auto-clear is disabled
        if not enabled and self.clear_timer_id:
            self.root.after_cancel(self.clear_timer_id)
            self.clear_timer_id = None
            print("‚ùå [UI] Cancelled pending subtitle clear timer")
        
        # Save preferences
        self.save_ui_preferences()
    
    def on_timeout_changed(self):
        """
        Handle auto-clear timeout duration changes.
        
        Called when user adjusts the timeout spinner.
        """
        timeout = self.subtitle_timeout_seconds.get()
        print(f"‚è∞ [UI] Auto-clear timeout changed to: {timeout} seconds")
        
        # Save preferences
        self.save_ui_preferences()
    
    def on_rate_limit_changed(self):
        """
        Handle API rate limit changes.
        
        Called when user adjusts the rate limit spinner.
        """
        new_rate = self.api_rate_var.get()
        self.min_api_interval = new_rate
        print(f"üö¶ [BANDWIDTH] API rate limit changed to: {new_rate} seconds")
        
        # Save preferences
        self.save_ui_preferences()
    
    def on_pause_threshold_changed(self):
        """
        Handle speech pause threshold changes.
        
        Called when user adjusts the pause threshold spinner.
        """
        new_threshold = self.pause_threshold_var.get()
        self.SILENCE_THRESHOLD = new_threshold
        print(f"üé§ [SPEECH] Pause threshold changed to: {new_threshold} seconds")
        
        # Save preferences
        self.save_ui_preferences()
    
    def schedule_subtitle_clear(self):
        """
        Schedule the subtitle to be cleared after the configured timeout.
        
        This method:
        1. Cancels any existing clear timer
        2. Schedules a new clear operation if auto-clear is enabled
        3. Uses tkinter's after() method for thread-safe UI updates
        """
        # Cancel any existing timer
        if self.clear_timer_id:
            self.root.after_cancel(self.clear_timer_id)
            self.clear_timer_id = None
        
        # Schedule new clear timer if auto-clear is enabled
        if self.auto_clear_enabled.get():
            timeout_ms = self.subtitle_timeout_seconds.get() * 1000  # Convert to milliseconds
            self.clear_timer_id = self.root.after(timeout_ms, self.clear_subtitle)
            print(f"‚è∞ [SUBTITLE] Scheduled subtitle clear in {self.subtitle_timeout_seconds.get()} seconds")
    
    def clear_subtitle(self):
        """
        Clear the subtitle display.
        
        Called by the timer when the timeout expires.
        Only clears if no new subtitle has been scheduled.
        """
        print("üßπ [SUBTITLE] Clearing subtitle due to timeout")
        self.text_label.configure(text="")
        self.clear_timer_id = None  # Reset timer ID

    def save_ui_preferences(self):
        """
        Save current UI preferences to settings file.
        """
        self.settings.save_ui_preferences(
            bg_color=self.bg_color.get(),
            text_color=self.text_color.get(),
            font_size=self.font_size.get(),
            language=self.selected_language.get(),
            recent_languages=self.recent_languages,
            auto_clear_enabled=self.auto_clear_enabled.get(),
            auto_clear_timeout=self.subtitle_timeout_seconds.get()
        )

    def load_ui_preferences(self):
        """
        Load and apply saved UI preferences.
        
        Called during app initialization to restore previous settings.
        """
        preferences = self.settings.load_ui_preferences()
        
        if preferences:
            # Apply loaded preferences
            self.bg_color.set(preferences.get("background_color", "black"))
            self.text_color.set(preferences.get("text_color", "white"))
            self.font_size.set(preferences.get("font_size", 24))
            self.selected_language.set(preferences.get("language", "English"))
            
            # Load recent languages
            self.recent_languages = preferences.get("recent_languages", [])
            
            # Load auto-clear preferences
            self.auto_clear_enabled.set(preferences.get("auto_clear_enabled", True))
            self.subtitle_timeout_seconds.set(preferences.get("auto_clear_timeout", 5))
            
            # Update the language menu with recent languages
            self.language_menu.configure(values=self.get_language_menu_list())
            
            # Update UI appearance with loaded settings
            self.update_background()
            self.update_text_color()
            self.update_font()
            
            print(f"‚úÖ [SETTINGS] Applied saved preferences: {preferences.get('background_color')} bg, {preferences.get('text_color')} text, {preferences.get('font_size')}px, {preferences.get('language')}")
            print(f"‚è∞ [SETTINGS] Auto-clear: {'Enabled' if preferences.get('auto_clear_enabled', True) else 'Disabled'} ({preferences.get('auto_clear_timeout', 5)}s timeout)")
            if self.recent_languages:
                print(f"üìù [SETTINGS] Loaded recent languages: {self.recent_languages}")

    def toggle_recording(self):
        """
        Toggle between recording and stopped states.
        
        This is the main control method that starts or stops the entire
        audio capture and processing pipeline.
        """
        print(f"üéôÔ∏è [RECORD] Toggle recording. Current state: {self.is_recording}")
        if not self.is_recording:
            self.start_recording()
        else:
            self.stop_recording()

    def start_recording(self):
        """
        Start the audio recording and processing pipeline.
        
        Process:
        1. Reset session counters and start tracking
        2. Update UI state (button text, status message)
        3. Set recording flag to True
        4. Start background recording thread
        
        The recording thread will continuously capture audio chunks
        and submit them for processing until stopped.
        """
        print("‚ñ∂Ô∏è [RECORD] Start recording pressed")
        
        # Reset session tracking for new session
        self.session_start_time = time.time()
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.total_cost = 0.0
        self.session_translations = 0
        print(f"üìä [SESSION] New session started at {time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        self.is_recording = True
        self.record_button.configure(text="Stop Recording")
        self.text_label.configure(text="")  # Keep overlay clean - no "Listening..." text
        
        # Start recording in separate thread to avoid blocking UI
        self.record_thread = threading.Thread(target=self.record_loop)
        self.record_thread.start()

    def stop_recording(self):
        """
        Stop the audio recording and processing pipeline.
        
        Process:
        1. Set recording flag to False (signals recording thread to stop)
        2. Generate end-of-session report
        3. Update UI state (button text, status message)
        
        The recording thread will finish its current chunk and then exit.
        """
        print("‚èπÔ∏è [RECORD] Stop recording pressed")
        self.is_recording = False
        
        # Record session end time and generate report
        self.session_end_time = time.time()
        print(f"üìä [SESSION] Session ended at {time.strftime('%Y-%m-%d %H:%M:%S')}")
        self.generate_session_report()
        
        self.record_button.configure(text="Start Recording")
        self.text_label.configure(text="")  # Clear overlay for clean stream appearance

    def record_loop(self):
        """
        IMPROVED: Smart audio recording loop with speech detection.
        
        This method now:
        1. Continuously buffers audio
        2. Detects when speech starts and stops
        3. Only processes complete sentences/phrases
        4. Dramatically reduces API calls by waiting for natural speech breaks
        """
        print("üéß [RECORD] Opening audio stream for smart recording")
        
        # Open audio stream with configured parameters
        stream = self.audio.open(format=self.FORMAT,
                               channels=self.CHANNELS,
                               rate=self.RATE,
                               input=True,  # Input stream (microphone)
                               frames_per_buffer=self.CHUNK)
        
        print("üî¥ [RECORD] Smart recording started...")
        
        while self.is_recording:
            # Read single chunk of audio
            data = stream.read(self.CHUNK, exception_on_overflow=False)
            
            # Check if this chunk contains speech
            audio_data = np.frombuffer(data, dtype=np.int16)
            rms_volume = np.sqrt(np.mean(audio_data.astype(np.float32) ** 2))
            has_speech = rms_volume > 150  # Lowered threshold for better sensitivity (was 150)
            
            current_time = time.time()
            
            if has_speech:
                # Speech detected - add to buffer and reset silence timer
                self.speech_buffer.append(data)
                self.last_speech_time = current_time
                self.silence_start_time = None
                
                # Safety mechanism: if buffer gets too long, process it to avoid missing long statements
                buffer_duration = len(self.speech_buffer) * self.CHUNK / self.RATE
                if buffer_duration > 10.0:  # Process if more than 10 seconds of continuous speech
                    print(f"‚ö†Ô∏è [SMART] Buffer too long ({buffer_duration:.1f}s), processing to avoid missing content")
                    self.audio_task_queue.put(self.speech_buffer.copy())
                    self.speech_buffer = []
                else:
                    print(f"üé§ [SMART] Speech detected, buffer size: {len(self.speech_buffer)} chunks ({buffer_duration:.1f}s)")
                
            else:
                # No speech detected
                if self.silence_start_time is None and self.speech_buffer:
                    # Start of silence after speech
                    self.silence_start_time = current_time
                    print("ü§´ [SMART] Silence started, waiting for speech completion...")
                
                elif self.silence_start_time is not None:
                    # Continue silence - check if we should process
                    silence_duration = current_time - self.silence_start_time
                    buffer_duration = len(self.speech_buffer) * self.CHUNK / self.RATE
                    
                    if (silence_duration >= self.SILENCE_THRESHOLD and 
                        buffer_duration >= self.MIN_SPEECH_LENGTH and
                        self.speech_buffer):
                        
                        print(f"‚úÖ [SMART] Processing complete speech: {buffer_duration:.1f}s after {silence_duration:.1f}s silence")
                        
                        # Process the accumulated speech
                        self.audio_task_queue.put(self.speech_buffer.copy())
                        
                        # Clear buffer for next speech
                        self.speech_buffer = []
                        self.silence_start_time = None
            
            # Small delay to prevent excessive CPU usage
            time.sleep(0.01)
        
        # Process any remaining speech when stopping
        if self.speech_buffer:
            buffer_duration = len(self.speech_buffer) * self.CHUNK / self.RATE
            if buffer_duration >= self.MIN_SPEECH_LENGTH:
                print(f"üîÑ [SMART] Processing final speech buffer: {buffer_duration:.1f}s")
                self.audio_task_queue.put(self.speech_buffer.copy())
        
        # Clean up audio stream
        stream.stop_stream()
        stream.close()
        print("üõë [RECORD] Smart recording stopped.")

    def audio_worker(self):
        """
        Audio processing worker thread.
        
        This thread:
        1. Monitors the audio task queue for new audio chunks
        2. Submits each chunk to the thread pool for processing
        3. Runs continuously until application shutdown
        
        Using a thread pool allows for potentially parallel processing
        of multiple audio chunks if needed in the future.
        """
        print("üõ†Ô∏è [AUDIO] Audio worker thread started")
        
        while True:
            # Wait for audio chunk from recording thread
            frames = self.audio_task_queue.get()
            
            if frames is None:  # Shutdown signal
                print("üõë [AUDIO] Audio worker thread exiting")
                break
            
            print("üõ†Ô∏è [AUDIO] Processing frames from queue")
            # Submit to thread pool for processing
            self.audio_executor.submit(self.process_audio, frames)

    def process_audio(self, frames):
        """
        Process audio chunk through Whisper speech-to-text.
        
        Args:
            frames: List of audio data chunks from microphone
            
        Process:
        1. Check audio level for voice activity detection
        2. Create temporary WAV file from audio frames
        3. Run Whisper transcription on the audio file
        4. Extract text from transcription result
        5. Submit text for translation (if any text was detected)
        6. Clean up temporary file
        
        This method runs in the thread pool to avoid blocking other operations.
        """
        print("üßÅ [AUDIO] Processing audio frames...")
        
        # Check if Whisper model is available
        if self.whisper_model is None:
            print("‚ùå [AUDIO] Whisper model not available. Skipping transcription.")
            return
        
        # Voice Activity Detection - check if audio has sufficient volume
        # Convert audio frames to numpy array for analysis
        audio_data = np.frombuffer(b''.join(frames), dtype=np.int16)
        
        # Calculate RMS (Root Mean Square) volume level
        rms_volume = np.sqrt(np.mean(audio_data.astype(np.float32) ** 2))
        
        # Set threshold for voice activity (adjust this value as needed)
        # Lower values = more sensitive, higher values = less sensitive
        voice_threshold = 150  # Lowered threshold for better sensitivity (matches smart recording)
        
        print(f"üîä [AUDIO] Audio RMS level: {rms_volume:.1f} (threshold: {voice_threshold})")
        
        if rms_volume < voice_threshold:
            print("ü§´ [AUDIO] Audio level too low - likely silence or background noise. Skipping transcription.")
            return
        
        # Create temporary WAV file in the app directory (not system temp - avoids permission issues)
        temp_filename = f"temp_audio_{int(time.time() * 1000)}.wav"  # Unique filename with timestamp
        temp_filepath = os.path.join(os.getcwd(), temp_filename)
        
        try:
            # Set up WAV file with correct audio parameters
            wf = wave.open(temp_filepath, 'wb')
            wf.setnchannels(self.CHANNELS)
            wf.setsampwidth(self.audio.get_sample_size(self.FORMAT))
            wf.setframerate(self.RATE)
            wf.writeframes(b''.join(frames))  # Combine all audio chunks
            wf.close()
            
            print(f"üìÇ [AUDIO] Temporary wav file created: {temp_filepath}")
            
            # Run Whisper transcription
            print("ü§ñ [AUDIO] Calling whisper transcribe...")
            result = self.whisper_model.transcribe(temp_filepath)
            text = result["text"].strip()  # Extract transcribed text
            print(f"üìù [AUDIO] Whisper transcription: '{text}'")
            
            if text:  # Only process if we got actual text
                print("üåç [AUDIO] Sending translation to worker thread")
                self.translation_task_queue.put(text)
            else:
                print("ü§î [AUDIO] No transcription text returned")
                
        except Exception as e:
            print(f"‚ùóError processing audio: {e}")
        finally:
            # Always clean up temporary file - this will work because it's in our own directory
            try:
                if os.path.exists(temp_filepath):
                    print(f"üóëÔ∏è [AUDIO] Removing temp file {temp_filepath}")
                    os.remove(temp_filepath)
                    print(f"‚úÖ [AUDIO] Successfully removed temp file")
                else:
                    print(f"‚ö†Ô∏è [AUDIO] Temp file already removed: {temp_filepath}")
            except Exception as cleanup_error:
                print(f"‚ùå [AUDIO] Error removing temp file {temp_filepath}: {cleanup_error}")

    def translation_worker(self):
        """
        Translation worker thread.
        
        This thread:
        1. Monitors the translation task queue for text to process
        2. Formats and translates text using OpenAI GPT
        3. Submits processed text to UI queue for display
        4. Runs continuously until application shutdown
        
        Separating translation into its own thread prevents OpenAI API
        calls from blocking audio processing or UI updates.
        """
        print("üåê [TRANSLATE] Translation worker thread started")
        
        while True:
            # Wait for text from audio processing
            text = self.translation_task_queue.get()
            
            if text is None:  # Shutdown signal
                print("üõë [TRANSLATE] Translation worker exiting")
                break
            
            print(f"üåê [TRANSLATE] Processing text for translation: '{text}'")
            
            # Process text through OpenAI
            translated = self.format_and_translate_sync(text)
            
            if translated:
                print(f"üì¨ [TRANSLATE] Putting translated text in UI queue: '{translated}'")
                self.text_queue.put(translated)  # Send to UI for display
            else:
                print("üòø [TRANSLATE] No translated text returned")

    def format_and_translate_sync(self, text):
        """
        IMPROVED: Format and translate text with rate limiting and duplicate detection.
        
        Args:
            text (str): Raw transcribed text from Whisper
            
        Returns:
            str: Formatted and translated text, or original text if error
            
        IMPROVEMENTS:
        1. Rate limiting prevents API spam
        2. Duplicate detection avoids re-translating same text
        3. Intelligent text similarity checking
        4. Bandwidth-conscious processing
        """
        # Check if OpenAI client is available
        if self.client is None:
            print("‚ùå [TRANSLATE] OpenAI client not available. Returning original text.")
            return text
        
        # Rate limiting check
        current_time = time.time()
        if current_time - self.last_api_call_time < self.min_api_interval:
            remaining_time = self.min_api_interval - (current_time - self.last_api_call_time)
            print(f"‚è≥ [TRANSLATE] Rate limited - waiting {remaining_time:.1f}s before next API call")
            time.sleep(remaining_time)
            current_time = time.time()
        
        # Duplicate detection - check if we've recently translated similar text (less aggressive)
        text_normalized = text.lower().strip()
        for recent_text in self.recent_translations:
            if self.text_similarity(text_normalized, recent_text.lower().strip()) > 0.9:  # Raised from 0.8 to 0.9
                print(f"üîÑ [TRANSLATE] Skipping duplicate/similar text: '{text}'")
                return text  # Return original if too similar to recent translation
        
        # Add to recent translations list
        self.recent_translations.append(text)
        if len(self.recent_translations) > self.max_recent_translations:
            self.recent_translations.pop(0)  # Remove oldest
            
        # Get target language code
        target_lang = self.languages[self.selected_language.get()]
        print(f"üåê [TRANSLATE] Formatting/translating to {self.selected_language.get()} ({target_lang})")
        
        try:
            # Create prompt based on target language
            if target_lang == "en":
                # English: format and correct only
                prompt = f"Format the following transcribed text with proper capitalization, punctuation, and spelling corrections. Keep the meaning exactly the same:\n\n{text}"
            else:
                # Other languages: format and translate
                prompt = f"Format the following transcribed text with proper capitalization, punctuation, and spelling corrections, then translate it to {self.selected_language.get()}. Use informal, conversational language appropriate for live streaming. Return only the translated text, nothing else:\n\n{text}"
            
            print(f"üì§ [TRANSLATE] Prompt sent to OpenAI: {prompt[:100]}{'...' if len(prompt)>100 else ''}")
            
            # Call OpenAI API with optimized parameters
            response = self.client.chat.completions.create(
                model="gpt-4.1-nano",  # Fast, cost-effective model for real-time use
                messages=[
                    {"role": "system", "content": "You are a professional translator and editor who specializes in informal, conversational translations for live streaming."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # Low temperature for consistent, accurate translations
                max_tokens=200  # Limit response length for subtitle use
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # Log token usage and calculate costs
            self.log_token_usage(response)
            
            # Update rate limiting timestamp
            self.last_api_call_time = time.time()
            
            print(f"üíå [TRANSLATE] Received translation: '{result_text}'")
            return result_text
            
        except Exception as e:
            print(f"‚ùóError in formatting/translation: {e}")
            return text  # Return original text if translation fails
    
    def text_similarity(self, text1, text2):
        """
        Calculate similarity between two text strings using word overlap.
        
        Args:
            text1, text2 (str): Texts to compare
            
        Returns:
            float: Similarity score between 0.0 and 1.0
        """
        if not text1 or not text2:
            return 0.0
            
        # Simple word-based similarity
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 or not words2:
            return 0.0
            
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0

    def log_token_usage(self, response):
        """
        Log token usage and calculate cost estimation for OpenAI API calls.
        
        Args:
            response: OpenAI API response object containing usage statistics
            
        GPT-4.1 nano pricing (per 1M tokens):
        - Input tokens: $0.10
        - Output tokens: $0.40
        - Cached input: $0.025 (not tracked separately for simplicity)
        """
        try:
            # Extract token usage from API response
            usage = response.usage
            input_tokens = usage.prompt_tokens
            output_tokens = usage.completion_tokens
            total_tokens = usage.total_tokens
            
            # Calculate costs (convert from per-million to per-token rates)
            input_cost = (input_tokens / 1_000_000) * 0.10  # $0.10 per 1M input tokens
            output_cost = (output_tokens / 1_000_000) * 0.40  # $0.40 per 1M output tokens
            total_cost = input_cost + output_cost
            
            # Update session totals
            self.total_input_tokens += input_tokens
            self.total_output_tokens += output_tokens
            self.total_cost += total_cost
            self.session_translations += 1
            
            # Log current API call details
            print(f"üí∞ [COST] Translation #{self.session_translations}")
            print(f"üí∞ [COST] Input: {input_tokens} tokens (${input_cost:.6f})")
            print(f"üí∞ [COST] Output: {output_tokens} tokens (${output_cost:.6f})")
            print(f"üí∞ [COST] This call: ${total_cost:.6f}")
            
            # Log session totals
            print(f"üí∞ [COST] === SESSION TOTALS ===")
            print(f"üí∞ [COST] Total translations: {self.session_translations}")
            print(f"üí∞ [COST] Total input tokens: {self.total_input_tokens:,}")
            print(f"üí∞ [COST] Total output tokens: {self.total_output_tokens:,}")
            print(f"üí∞ [COST] Total session cost: ${self.total_cost:.6f}")
            
            # Cost per translation average
            avg_cost = self.total_cost / self.session_translations if self.session_translations > 0 else 0
            print(f"üí∞ [COST] Average cost per translation: ${avg_cost:.6f}")
            print(f"üí∞ [COST] ========================")
            
        except Exception as e:
            print(f"‚ùóError logging token usage: {e}")

    def generate_session_report(self):
        """
        Generate and save a detailed session report to file.
        
        Creates a timestamped text file with comprehensive session statistics
        including duration, token usage, costs, and efficiency metrics.
        """
        try:
            # Skip report generation if no session data
            if self.session_start_time is None or self.session_end_time is None:
                print("‚ö†Ô∏è [SESSION] No session data available for report generation")
                return
            
            # Calculate session duration
            duration_seconds = self.session_end_time - self.session_start_time
            duration_minutes = duration_seconds / 60
            duration_str = f"{int(duration_minutes)} minutes {int(duration_seconds % 60)} seconds"
            
            # Create expense reports directory if it doesn't exist
            reports_dir = "expense_reports"
            if not os.path.exists(reports_dir):
                os.makedirs(reports_dir)
                print(f"üìÅ [SESSION] Created expense reports directory: {reports_dir}")
            
            # Generate timestamp for filename
            timestamp = time.strftime('%Y-%m-%d_%H-%M-%S', time.localtime(self.session_start_time))
            filename = os.path.join(reports_dir, f"session_report_{timestamp}.txt")
            
            # Calculate efficiency metrics
            translations_per_minute = self.session_translations / duration_minutes if duration_minutes > 0 else 0
            avg_tokens_per_translation = (self.total_input_tokens + self.total_output_tokens) / self.session_translations if self.session_translations > 0 else 0
            cost_per_minute = self.total_cost / duration_minutes if duration_minutes > 0 else 0
            projected_hourly_cost = cost_per_minute * 60
            
            # Generate report content
            report_content = f"""=== TWCC Translation Session Report ===
Session Date: {time.strftime('%Y-%m-%d', time.localtime(self.session_start_time))}
Start Time: {time.strftime('%H:%M:%S', time.localtime(self.session_start_time))}
End Time: {time.strftime('%H:%M:%S', time.localtime(self.session_end_time))}
Duration: {duration_str}

TRANSLATION STATS:
- Total Translations: {self.session_translations}
- Target Language: {self.selected_language.get()}
- Translations per minute: {translations_per_minute:.1f}

TOKEN USAGE:
- Total Input Tokens: {self.total_input_tokens:,}
- Total Output Tokens: {self.total_output_tokens:,}
- Total Tokens: {(self.total_input_tokens + self.total_output_tokens):,}

COST BREAKDOWN:
- Input Cost: ${(self.total_input_tokens / 1_000_000) * 0.10:.6f}
- Output Cost: ${(self.total_output_tokens / 1_000_000) * 0.40:.6f}
- Total Session Cost: ${self.total_cost:.6f}
- Average Cost per Translation: ${(self.total_cost / self.session_translations if self.session_translations > 0 else 0):.6f}

EFFICIENCY METRICS:
- Tokens per translation (avg): {avg_tokens_per_translation:.1f}
- Cost per minute: ${cost_per_minute:.6f}
- Projected hourly cost: ${projected_hourly_cost:.6f}

=== End of Report ===
"""
            
            # Write report to file
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"üìÑ [SESSION] Session report saved to: {filename}")
            print(f"üìä [SESSION] Summary: {self.session_translations} translations, ${self.total_cost:.6f} total cost")
            
        except Exception as e:
            print(f"‚ùóError generating session report: {e}")

    def update_text_loop(self):
        """
        UI update loop (runs in background thread).
        
        This thread:
        1. Monitors the text queue for new processed text
        2. Updates the subtitle display when new text arrives
        3. Schedules auto-clear timer for new subtitles
        4. Uses tkinter's thread-safe after() method for UI updates
        5. Runs continuously until application shutdown
        
        This separation ensures UI updates don't block audio processing
        and provides smooth, responsive subtitle display.
        """
        print("‚è≥ [THREAD] update_text_loop started")
        
        while True:
            try:
                # Wait for new text with short timeout
                text = self.text_queue.get(timeout=0.1)
                print(f"üì® [THREAD] Got text from queue: '{text}'")
                
                # Schedule UI update on main thread (thread-safe)
                def update_and_schedule_clear(t=text):
                    self.text_label.configure(text=t)
                    # Schedule auto-clear timer for this subtitle
                    self.schedule_subtitle_clear()
                
                self.root.after(0, update_and_schedule_clear)
                
            except queue.Empty:
                # Timeout is normal - continue loop
                pass
            except Exception as e:
                print(f"‚ùóError updating text: {e}")

    def cleanup_temp_files(self):
        """
        Clean up any leftover temporary WAV files from previous runs.
        
        This method runs at startup and shutdown to clean up any temporary files
        that weren't properly cleaned up from previous application runs.
        Now looks in the app directory instead of system temp folder.
        """
        try:
            # Look in the current app directory for temp audio files
            app_dir = os.getcwd()
            
            # Find all temp_audio_*.wav files in the app directory
            pattern = os.path.join(app_dir, "temp_audio_*.wav")
            temp_wav_files = glob.glob(pattern)
            
            if temp_wav_files:
                print(f"üßΩ [CLEANUP] Found {len(temp_wav_files)} temporary WAV files in app directory")
                
                cleaned_count = 0
                for temp_file in temp_wav_files:
                    try:
                        # Check if file is older than 5 minutes (likely from previous runs or crashes)
                        file_age = time.time() - os.path.getmtime(temp_file)
                        if file_age > 300:  # 5 minutes in seconds
                            os.remove(temp_file)
                            cleaned_count += 1
                            print(f"üóëÔ∏è [CLEANUP] Removed: {os.path.basename(temp_file)}")
                        else:
                            print(f"‚è≥ [CLEANUP] Skipping recent file: {os.path.basename(temp_file)}")
                    except Exception as e:
                        print(f"‚ùå [CLEANUP] Error removing {temp_file}: {e}")
                
                if cleaned_count > 0:
                    print(f"‚úÖ [CLEANUP] Cleaned up {cleaned_count} old temporary WAV files")
                else:
                    print("‚ÑπÔ∏è [CLEANUP] No old files to clean (all files are recent)")
            else:
                print("‚ú® [CLEANUP] No temporary WAV files found in app directory")
                
        except Exception as e:
            print(f"‚ùå [CLEANUP] Error during temp file cleanup: {e}")

    def cleanup(self):
        """
        Clean up resources and shut down background threads.
        
        Called when application is closing to ensure:
        1. Audio recording is stopped
        2. PyAudio resources are released
        3. Background threads are signaled to exit
        4. Thread pools are shut down properly
        5. Pending timers are cancelled
        
        This prevents resource leaks and ensures clean application shutdown.
        """
        print("üßπ [CLEANUP] Cleaning up, terminating PyAudio üì¥")
        
        # Clean up any remaining temp files
        self.cleanup_temp_files()
        
        # Stop recording
        self.is_recording = False
        
        # Cancel any pending subtitle clear timer
        if self.clear_timer_id:
            self.root.after_cancel(self.clear_timer_id)
            self.clear_timer_id = None
            print("‚ùå [CLEANUP] Cancelled pending subtitle clear timer")
        
        # Terminate audio system
        self.audio.terminate()
        
        # Shut down audio worker and thread pool
        self.audio_task_queue.put(None)  # Send shutdown signal
        self.audio_executor.shutdown(wait=False)
        
        # Shut down translation worker
        self.translation_task_queue.put(None)  # Send shutdown signal


def main():
    """
    Application entry point.
    
    Creates the main tkinter window, initializes the SubtitleApp,
    sets up proper cleanup on window close, and starts the main event loop.
    """
    print("üöÄ [MAIN] Starting app")
    
    # Create main window
    root = tk.Tk()
    
    # Initialize application
    app = SubtitleApp(root)
    
    # Set up proper cleanup when window is closed
    root.protocol("WM_DELETE_WINDOW", lambda: [app.cleanup(), root.destroy()])
    
    # Start main event loop
    root.mainloop()

if __name__ == "__main__":
    main()
